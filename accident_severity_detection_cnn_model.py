# -*- coding: utf-8 -*-
"""Accident_Severity_Detection_CNN_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KQJofV2yB5_6VmO9I3Nm9OCyEofbrb-R
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow
# %pip install tensorflow-gpu
# %pip install opencv-python
# %pip install matplotlib
# %pip install opencv-python
# %pip install cv2

# Commented out IPython magic to ensure Python compatibility.
# %pip install

import cv2
import os
import imghdr
import tensorflow as tf
import os
import matplotlib.pyplot as plt
import numpy as np

gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

directory = 'D:/DataAnalytics/Sem_04/Capstone/CNN/capstonedata/data/train'
image_exts = ['jpg']

os.listdir(directory)

from PIL import Image
from numpy import asarray

img = Image.open('D:/DataAnalytics/Sem_04/Capstone/CNN/capstonedata/data/train/Accident/acc1 (5).jpg')
img

numpydata = asarray(img)
numpydata.shape

img = Image.open('D:/DataAnalytics/Sem_04/Capstone/CNN/capstonedata/data/train/Accident/test_32.jpg')
img

numpydata = asarray(img)
numpydata.shape

for label in os.listdir(directory):
    for image in os.listdir(os.path.join(directory, label)):
        image_path = os.path.join(directory, label, image)
        img = cv2.imread(image_path)

data = tf.keras.utils.image_dataset_from_directory('D:/DataAnalytics/Sem_04/Capstone/CNN/capstonedata/data/train')

len(data)

data_iterator = data.as_numpy_iterator()
data_iterator

batch = data_iterator.next()
batch

fig, ax = plt.subplots(ncols=4, figsize=(20, 20))
for idx, img in enumerate(batch[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].set_title(batch[1][idx])
    ax[idx].axis('off')

data = data.map(lambda x,y: (x/255, y))

len(data)

data.as_numpy_iterator().next()

train_size = int(len(data) * 0.8)
val_size = int(len(data) * 0.2)

train_size

val_size

train = data.take(train_size)
val = data.skip(train_size).take(val_size)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

model = Sequential()
model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))
model.add(MaxPooling2D())
model.add(Conv2D(32, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())
model.add(Conv2D(16, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

from tensorflow.keras.optimizers import Adam
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

logdir  = 'logs'

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)

history = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])

plt.figure()
plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
fig.suptitle('Loss')
plt.legend(loc="upper right")
plt.show()

plt.figure()
plt.plot(history.history['accuracy'],label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
fig.suptitle('Accuracy')
plt.legend(loc="lower right")
plt.show()

from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy

precision,recall, accuracy = Precision(), Recall(), BinaryAccuracy()

test = tf.keras.utils.image_dataset_from_directory('D:/DataAnalytics/Sem_04/Capstone/CNN/capstonedata/data/test')

for batch in test.as_numpy_iterator():
    X, y = batch
    yhat = model.predict(X)
    precision.update_state(y, yhat)
    recall.update_state(y, yhat)
    accuracy.update_state(y, yhat)

print(f" Precision : {precision.result()}, \n Recall : { recall.result()}, \n Accuracy : { accuracy.result()}")

img = cv2.imread('D:/DataAnalytics/Sem_04/Capstone/CNN/capstonedata/data/test/Accident/test4_42.jpg')
plt.imshow(img)
plt.show()

resize = tf.image.resize(img, (256,256))
plt.imshow(resize.numpy().astype(int))
plt.show()

import numpy as np
yhat = model.predict(np.expand_dims(resize/255, 0))
yhat

if yhat > 0.5:
    print(f'Predicted class is Non Accident')
else:
    print(f'Predicted class is Accident')


#import pickle
#pickle.dump(model,open("model.pkl","wb"))

from keras.models import load_model
model.save('model.h5')